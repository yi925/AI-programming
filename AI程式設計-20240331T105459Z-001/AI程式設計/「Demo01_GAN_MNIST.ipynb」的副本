{"cells":[{"cell_type":"markdown","metadata":{"id":"8Gx_MkX-HA9a"},"source":["# 環境設定"]},{"cell_type":"markdown","metadata":{"id":"tfLiF0CMHfaW"},"source":["## 引入必要函式庫"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G3naEvMSGszc"},"outputs":[],"source":["import os\n","import sys\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","from keras.datasets import mnist\n","from keras.layers import Dense, Flatten, Reshape, LeakyReLU\n","from keras.models import Sequential\n","from keras.optimizers import Adam"]},{"cell_type":"markdown","metadata":{"id":"9SH9TcnKRQMO"},"source":["## 載入資料集"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":621,"status":"ok","timestamp":1702968719725,"user":{"displayName":"H Y","userId":"00495941265729836346"},"user_tz":-480},"id":"N1yvYHcLRUjN","outputId":"c776989a-4d03-473a-b6b0-bf338874516e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 0s 0us/step\n"]}],"source":["from keras.datasets import mnist\n","\n","(X_train, _), (_, _) = mnist.load_data()\n","\n","# Rescale -1 to 1 to fit tanh() activation function of Output Layer\n","X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n","\n","# Add a color channel dimension, from (60000, 28, 28) to (60000, 28, 28, 1)\n","X_train =  np.expand_dims(X_train, axis=3)"]},{"cell_type":"markdown","metadata":{"id":"K6uwrnucHj5d"},"source":["## 超參數設定"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SN3voGqgHZuk"},"outputs":[],"source":["# Set the shape of MNIST\n","img_rows = 28\n","img_cols = 28\n","channels = 1\n","\n","img_shape = (img_rows, img_cols, channels)\n","\n","# Set the length of noise for GANs generator Input Layer\n","z_dim = 100\n","\n","# Set the number of training epochs\n","epochs = 10000\n","\n","# Set the batch size\n","batch_size = 128\n","\n","# Set how many times of training should show acc / loss once\n","sample_interval = 100"]},{"cell_type":"markdown","metadata":{"id":"HDOHOqUHJALb"},"source":["# 定義模型"]},{"cell_type":"markdown","metadata":{"id":"Ps3_nMo1JC4w"},"source":["## 定義生成器（Generator）"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5LcCVXcDJGqo"},"outputs":[],"source":["def build_generator(img_shape, z_dim):\n","    model = Sequential()\n","    model.add(Dense(128, input_dim=z_dim))\n","    model.add(LeakyReLU(alpha=0.01))\n","    model.add(Dense(np.prod(img_shape), activation='tanh'))\n","    model.add(Reshape(img_shape))\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"BXoJdt4ZKIGw"},"source":["## 定義鑑別器（Discriminator）"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UgUT1RvUKM6M"},"outputs":[],"source":["def build_discriminator(img_shape):\n","    model = Sequential()\n","    model.add(Flatten(input_shape=img_shape))\n","    model.add(Dense(128))\n","    model.add(LeakyReLU(alpha=0.01))\n","    model.add(Dense(1, activation='sigmoid'))\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"imnkJnb2K1pF"},"source":["## 定義生成器與鑑別器組合函數"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U62L7I2sK7UH"},"outputs":[],"source":["def build_gan(generator, discriminator):\n","    model = Sequential()\n","    model.add(generator)\n","    model.add(discriminator)\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"wrfabzslLcPH"},"source":["## 生成整個 GAN 模型"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B4pTJMiZLjPS"},"outputs":[],"source":["# Create and Compile Discriminator\n","discriminator = build_discriminator(img_shape)\n","discriminator.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n","\n","# Create and Compile Generator\n","generator = build_generator(img_shape, z_dim)\n","\n","# Frozen the Discriminator's weights when training Generator\n","discriminator.trainable = False\n","\n","# Create and Compile GAN\n","gan = build_gan(generator, discriminator)\n","gan.compile(loss='binary_crossentropy', optimizer=Adam())"]},{"cell_type":"markdown","metadata":{"id":"AGJHrLsgUxyP"},"source":["# 訓練模型"]},{"cell_type":"markdown","metadata":{"id":"a0nhyib4XWqx"},"source":["## 定義訓練過程中，秀圖的函數"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QQ6hdMu3Xb3v"},"outputs":[],"source":["def sample_images(generator, image_grid_rows=4, image_grid_columns=4):\n","    # Sample random noise\n","    noise = np.random.normal(0, 1, (image_grid_rows * image_grid_columns, z_dim))\n","\n","    # Generate images from random noise\n","    gen_imgs = generator.predict(noise)\n","\n","    # Rescale image pixel values to [0, 1]\n","    gen_imgs = 0.5 * gen_imgs + 0.5\n","\n","    # Set image grid\n","    fig, axs = plt.subplots(image_grid_rows,\n","                            image_grid_columns,\n","                            figsize=(4, 4),\n","                            sharey=True,\n","                            sharex=True)\n","    cnt = 0\n","    for i in range(image_grid_rows):\n","        for j in range(image_grid_columns):\n","            # Output a grid of images\n","            axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n","            axs[i, j].axis('off')\n","            cnt += 1\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Zx-mx80-VBFZ"},"source":["## 定義訓練函數\n","\n","* 自訂訓練函數的原因：希望能觀察到「訓練到一半」所產生出來的圖片"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0BZHKZsiVNPg"},"outputs":[],"source":["losses = []\n","accuracies = []\n","iteration_checkpoints = []\n","\n","def train(iterations, batch_size, sample_interval):\n","    # Labels for real images: all ones\n","    real = np.ones((batch_size, 1))\n","\n","    # Labels for fake images: all zeros\n","    fake = np.zeros((batch_size, 1))\n","\n","    for iteration in range(iterations):\n","\n","        # Turn off the stdout temporarily\n","        # To supress 4/4 [=====================] - 0s 3ms/step\n","        original_stdout = sys.stdout\n","        sys.stdout = open(os.devnull, 'w')\n","\n","        # ---- Train the Discriminator ----\n","\n","        # Get a random batch of real images\n","        idx = np.random.randint(0, X_train.shape[0], batch_size)\n","        imgs = X_train[idx]\n","\n","        # Sample noise and generate a batch of fake images\n","        noise = np.random.normal(0, 1, (batch_size, z_dim))\n","        gen_imgs = generator.predict(noise)\n","\n","        # Train Discriminator\n","        d_loss_real = discriminator.train_on_batch(imgs, real)\n","        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n","        d_loss, accuracy = 0.5 * np.add(d_loss_real, d_loss_fake)\n","\n","        # ---- Train the Generator ----\n","\n","        # Generate a batch of fake images\n","        noise = np.random.normal(0, 1, (batch_size, z_dim))\n","\n","        # Set the Noise as True in purpose\n","        g_loss = gan.train_on_batch(noise, real)\n","\n","        # Turn stdout back on\n","        sys.stdout.close()\n","        sys.stdout = original_stdout\n","\n","        if (iteration + 1) % sample_interval == 0:\n","\n","            # Save losses and accuracies so they can be plotted after training\n","            losses.append((d_loss, g_loss))\n","            accuracies.append(100.0 * accuracy)\n","            iteration_checkpoints.append(iteration + 1)\n","\n","            # Output training progress\n","            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" %\n","                (iteration + 1, d_loss, 100.0 * accuracy, g_loss))\n","\n","            # Output a sample of generated image\n","            sample_images(generator)"]},{"cell_type":"markdown","metadata":{"id":"z2p_T4GNZCXi"},"source":["## 開始訓練模型"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1CNY8uxzAv-o0J5iQd51YElmmY6O68GAr"},"id":"sWVF9zixZEnG","outputId":"9dec0d02-ce76-4064-a822-22e27bbd216a"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["train(iterations=epochs, batch_size=batch_size, sample_interval=sample_interval)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"19aDjA-HDP-Oq2xMa8KfbuHEqAD_jjuwC","timestamp":1702968562539}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}